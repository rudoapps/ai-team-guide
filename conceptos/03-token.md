# Token

## ¬øQu√© es un Token?

**Definici√≥n simple:** Las piezas peque√±as en que la IA divide el texto para procesarlo.

**Analog√≠a:** Como dividir un puzzle complejo en piezas manejables, o como las "unidades de lectura" de la IA.

## C√≥mo Funcionan los Tokens

Los tokens **no son siempre palabras completas**, sino fragmentos significativos:

### Ejemplos de Tokenizaci√≥n

**Palabras comunes** = 1 token:
- "el" = 1 token
- "y" = 1 token
- "gato" = 1 token
- "c√≥digo" = 1 token

**Palabras largas** pueden ser 1 o m√°s tokens:
- "desarrollador" = 1-2 tokens
- "refactorizaci√≥n" = 2-3 tokens
- "telecomunicaciones" = 3 tokens

**C√≥digo** tiene su propia l√≥gica:
```javascript
function suma(a, b) { return a + b; }
```
‚âà 15-20 tokens (espacios, par√©ntesis, palabras clave)

**N√∫meros y s√≠mbolos**:
- "123" = 1 token
- "1.234,56" = 4-5 tokens
- "!!!" = 3 tokens

### Desglose Real

**Texto**: `"¬°Hola! ¬øC√≥mo est√°s?"`

**Tokens**:
1. "¬°Hola"
2. "!"
3. "¬ø"
4. "C√≥mo"
5. "est√°s"
6. "?"

**Total**: 6 tokens

## Por Qu√© Importan los Tokens

### 1. Impacto en el Coste üí∞

Los servicios de IA cobran por token procesado:
- **Input tokens**: Tu prompt
- **Output tokens**: La respuesta

**Ejemplo de coste:**
```
Tu prompt: 100 tokens
Respuesta: 500 tokens
Total: 600 tokens

Si GPT-4 cuesta $0.03 por 1K tokens input y $0.06 por 1K output:
Coste = (100 √ó 0.03/1000) + (500 √ó 0.06/1000)
      = $0.003 + $0.03
      = $0.033 (‚âà 3 c√©ntimos)
```

### 2. L√≠mites de Longitud üìè

Cada modelo tiene una **ventana de contexto** (m√°ximo de tokens):

| Modelo | Contexto M√°ximo | Equivalente |
|--------|----------------|-------------|
| GPT-3.5 | 16K tokens | ~12 p√°ginas |
| GPT-4 | 8K-128K tokens | ~6-100 p√°ginas |
| Claude 3 | 200K tokens | ~150 p√°ginas |

**¬øQu√© pasa si excedes el l√≠mite?**
- La IA "olvida" mensajes antiguos
- Documentos grandes se truncan
- Conversaciones largas pierden contexto inicial

### 3. Impacto en Rendimiento ‚ö°

M√°s tokens = m√°s lento y m√°s caro

**Buena pr√°ctica:**
- Prompts concisos pero claros
- Divide tareas grandes en chunks peque√±os
- Usa el modelo apropiado para el tama√±o

## Estimaci√≥n de Tokens

**Reglas r√°pidas:**
- **1 token ‚âà 4 caracteres** (incluyendo espacios)
- **1 token ‚âà 0.75 palabras** (en espa√±ol)
- **100 palabras ‚âà 130-150 tokens**
- **1 p√°gina de c√≥digo ‚âà 500-800 tokens**

**Herramientas:**
- OpenAI Tokenizer (online)
- Palabra/caracteres √∑ 4 (estimaci√≥n r√°pida)

## Estrategias Pr√°cticas

### Escribir Prompts Eficientes

‚ùå **Ineficiente** (desperdicia tokens):
```
Realmente agradecer√≠a si pudieras por favor ayudarme
a escribir una funci√≥n que sume dos n√∫meros en JavaScript
porque no estoy seguro de c√≥mo hacerlo y ser√≠a genial
si me explicaras tambi√©n c√≥mo funciona.
```
*~50 tokens*

‚úÖ **Eficiente** (ahorra tokens):
```
Crea una funci√≥n en JavaScript que sume dos n√∫meros.
Incluye explicaci√≥n breve.
```
*~15 tokens*

### Manejar Documentos Largos

**Problema**: Archivo de 100 p√°ginas excede l√≠mite

**Soluciones**:
1. **Fragmentar**: Procesar 20 p√°ginas a la vez
2. **Resumir primero**: Extraer puntos clave, luego profundizar
3. **Extraer secciones**: Trabajar solo con partes relevantes
4. **Usar modelos grandes**: Claude 3 (200K contexto)

### Optimizar Conversaciones Largas

**Problema**: Conversaci√≥n de 50 mensajes pierde contexto inicial

**Soluciones**:
1. **Reset peri√≥dico**: Iniciar nueva conversaci√≥n
2. **Checkpoint summaries**: Resumir cada 10-15 mensajes
3. **Context anchoring**: Recordar informaci√≥n clave

Ejemplo:
```
Recordatorio del contexto:
- Proyecto: App de ecommerce en React Native
- Stack: Node.js + PostgreSQL
- Trabajando en: Sistema de pagos

Ahora, continuando con...
```

## Casos de Uso por Rol

### Desarrolladores

**C√≥digo simple** (~100-500 tokens):
```
Crea funci√≥n de validaci√≥n de email en Python.
Usa regex, retorna bool.
```

**Refactoring** (~2K-10K tokens):
```
[Pega clase completa]
Refactoriza siguiendo principios SOLID.
```

**Code review** (~5K-20K tokens):
```
[Pega m√∫ltiples archivos]
Revisa y sugiere mejoras.
```

### Dise√±adores

**Design tokens** (~500-1K tokens):
```
Genera estructura de design tokens en JSON.
Incluye: colors, typography, spacing.
```

**Component specs** (~1K-3K tokens):
```
Describe sistema de componentes de botones.
Estados, tama√±os, variantes.
```

## Problemas Comunes

### "Conversaci√≥n Demasiado Larga"
**S√≠ntoma**: Error de l√≠mite de contexto
**Soluci√≥n**: Nueva conversaci√≥n + resumen del contexto

### "Respuesta Incompleta"
**S√≠ntoma**: IA se detiene a mitad
**Soluci√≥n**: "Contin√∫a" o divide solicitud

### Costes Inesperados
**S√≠ntoma**: Factura alta
**Soluci√≥n**:
- Monitorear uso
- Usar modelos econ√≥micos para tareas simples
- Prompts m√°s concisos

## Consejos para Ahorrar Tokens (y Dinero)

1. **S√© conciso**: Elimina palabras innecesarias
2. **Reutiliza contexto**: Construye sobre respuestas previas
3. **Elige modelo correcto**: No uses GPT-4 para tareas simples
4. **Agrupa solicitudes**: M√∫ltiples preguntas en un prompt
5. **Usa ejemplos con moderaci√≥n**: Cada ejemplo suma tokens

## Conclusi√≥n Clave

Los tokens son la **moneda de la IA**:
- Determinan tus costes
- Limitan cu√°nto procesas
- Afectan velocidad

**Regla pr√°ctica:** S√© consciente de tokens, pero no te obsesiones. Enf√≥cate en claridad primero, optimizaci√≥n despu√©s.

## Relaci√≥n con Otros Conceptos

- **[Modelo](./02-modelo.md)**: Cada modelo cobra diferente por token
- **[Contexto](./04-contexto.md)**: El contexto consume tokens
- **[Prompt](./05-prompt.md)**: Prompts m√°s largos = m√°s tokens = m√°s coste

---

**Siguiente**: Aprende sobre [Contexto](./04-contexto.md) y c√≥mo dar informaci√≥n efectiva a la IA.

[‚Üê Volver a Conceptos](../README.md#conceptos)
