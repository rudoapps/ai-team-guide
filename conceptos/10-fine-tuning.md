# Fine-tuning

## ¬øQu√© es el Fine-tuning?

**Definici√≥n simple:** Tomar un modelo de IA general y entrenarlo con datos espec√≠ficos de tu dominio, empresa o proyecto para especializarlo.

**Analog√≠a:** Es como contratar un **desarrollador senior general** (modelo base) y darle **3 meses de onboarding intensivo** en tu stack, tus patrones, tu c√≥digo - convirti√©ndolo en especialista de tu proyecto.

```
Modelo Base: "S√© JavaScript, React, Node.js en general"
Modelo Fine-tuned: "S√© espec√≠ficamente c√≥mo tu equipo estructura
                    componentes, tus naming conventions,
                    tus patterns de testing, tu arquitectura"
```

## Por Qu√© Hacer Fine-tuning

### Problema con Modelos Base

**Chat con GPT-4 base**:
```javascript
T√∫: "Crea un componente Button siguiendo nuestras convenciones"

GPT-4: [Genera c√≥digo gen√©rico]
import React from 'react';
import styles from './Button.css';

export function Button({ label, onClick }) {
  return <button onClick={onClick}>{label}</button>;
}
```
*Funcional, pero no sigue TUS convenciones espec√≠ficas*

### Con Fine-tuning

**Chat con GPT-4 fine-tuned con tu codebase**:
```typescript
T√∫: "Crea un componente Button siguiendo nuestras convenciones"

GPT-4-tuned:
import { FC } from 'react';
import styled from 'styled-components';
import { ButtonProps } from '@/types/components';
import { useAnalytics } from '@/hooks';

export const Button: FC<ButtonProps> = ({
  variant = 'primary',
  size = 'md',
  label,
  onClick,
  ...props
}) => {
  const { trackClick } = useAnalytics();

  const handleClick = (e) => {
    trackClick('button', { variant, label });
    onClick?.(e);
  };

  return (
    <StyledButton
      variant={variant}
      size={size}
      onClick={handleClick}
      {...props}
    >
      {label}
    </StyledButton>
  );
};

const StyledButton = styled.button<{variant: string; size: string}>`
  // Usa tus design tokens
`;
```
*Sigue exactamente tus patrones: styled-components, analytics, props structure, naming*

## Casos de Uso en Desarrollo

### 1. Patrones de C√≥digo Espec√≠ficos üéØ

**Sin fine-tuning**:
- Genera c√≥digo "standard" gen√©rico
- No conoce tus naming conventions
- Usa patterns diferentes a los tuyos

**Con fine-tuning**:
- Genera c√≥digo que parece escrito por tu equipo
- Respeta tus guidelines autom√°ticamente
- Usa tus librer√≠as y helpers preferidos

**Ejemplo**:
```
Training data: 500 componentes de tu proyecto
Resultado: IA genera componentes indistinguibles de los reales
```

### 2. Stack Tecnol√≥gico Espec√≠fico üõ†Ô∏è

**Sin fine-tuning**:
```python
T√∫: "Crea endpoint para crear usuario"

IA: [Genera con Express + MongoDB gen√©rico]
```

**Con fine-tuning en tu stack**:
```python
T√∫: "Crea endpoint para crear usuario"

IA: [Genera con tu stack exacto]
- FastAPI + Pydantic
- Tu estructura de validators
- Tu manera de handle errors
- Tus decorators custom
- Tu logging system
```

### 3. Design System y Componentes üé®

**Training con tu design system**:
```
Data: Todos tus componentes + Storybook stories
Resultado: IA que genera componentes perfectamente
           integrados con tu design system
```

**Ejemplo**:
```typescript
T√∫: "Crea modal de confirmaci√≥n"

IA fine-tuned genera:
- Usa tus tokens de spacing
- Aplica tus animation utilities
- Estructura seg√∫n tu pattern de modals
- Props tipadas seg√∫n tus conventions
- Accesibilidad seg√∫n tus standards
```

### 4. Testing Conventions üß™

**Training con tus tests**:
```
Data: Todos tus archivos .test.ts
Resultado: IA que escribe tests como tu equipo
```

**Ejemplo**:
```typescript
T√∫: "Escribe tests para el componente Button"

IA fine-tuned:
import { render, screen, userEvent } from '@testing-library/react';
import { Button } from './Button';

describe('Button', () => {
  it('renders with correct label', () => {
    render(<Button label="Click me" />);
    expect(screen.getByRole('button')).toHaveTextContent('Click me');
  });

  it('calls onClick handler when clicked', async () => {
    const handleClick = jest.fn();
    render(<Button label="Click" onClick={handleClick} />);

    await userEvent.click(screen.getByRole('button'));

    expect(handleClick).toHaveBeenCalledTimes(1);
  });

  it('tracks analytics on click', async () => {
    const { trackClick } = useAnalytics();
    // ... sigue tu patr√≥n de testing de analytics
  });
});
```

## Proceso de Fine-tuning

### Fase 1: Recolecci√≥n de Datos üìä

**Para proyecto de desarrollo**:
```bash
Datos a incluir:
‚úì Todo tu c√≥digo fuente (src/)
‚úì Tests y sus patrones
‚úì Configuraciones (tsconfig, webpack, etc.)
‚úì Documentaci√≥n interna
‚úì Pull requests y code reviews
‚úì Guidelines y style guides
‚úì Commits messages (para aprender tu estilo)
```

**Calidad > Cantidad**:
```
‚ùå 10,000 archivos mal estructurados
‚úÖ 1,000 archivos bien seleccionados y representativos
```

### Fase 2: Preparaci√≥n y Limpieza üßπ

```bash
# Eliminar datos sensibles
grep -r "API_KEY\|PASSWORD\|SECRET" src/
# ‚Üí Remover o reemplazar

# Eliminar c√≥digo deprecated
find src/ -name "*.old.ts"
# ‚Üí No incluir en training

# Formatear consistentemente
npm run prettier
# ‚Üí C√≥digo limpio para training
```

**Estructura recomendada**:
```json
[
  {
    "prompt": "Create a button component with primary variant",
    "completion": "import { FC } from 'react';\nimport styled from..."
  },
  {
    "prompt": "Write test for button click handler",
    "completion": "describe('Button', () => {\n  it('calls onClick..."
  }
]
```

### Fase 3: Training üèãÔ∏è

**Opciones**:

**OpenAI Fine-tuning**:
```bash
# Preparar dataset
openai tools fine_tunes.prepare_data -f training_data.jsonl

# Iniciar fine-tune
openai api fine_tunes.create \
  -t "training_data.jsonl" \
  -m "gpt-3.5-turbo" \
  --suffix "my-company-code"
```

**Anthropic Claude**:
```python
# Via API (contactar sales para fine-tuning)
import anthropic

client = anthropic.Client(api_key="...")
# Fine-tuning enterprise
```

**Self-hosted (LoRA)**:
```python
# Para modelos open source
from transformers import AutoModelForCausalLM
from peft import LoraConfig, get_peft_model

model = AutoModelForCausalLM.from_pretrained("codellama/CodeLlama-7b")
lora_config = LoraConfig(r=8, lora_alpha=32)
model = get_peft_model(model, lora_config)
# ... training loop
```

### Fase 4: Validaci√≥n ‚úÖ

**Test suite para modelo**:
```typescript
// Validation prompts
const validationTests = [
  {
    prompt: "Create React component with styled-components",
    expectContains: ["import styled", "const Styled", "FC<"],
    expectNotContains: ["import './styles.css'"]
  },
  {
    prompt: "Write unit test for function",
    expectContains: ["describe(", "it(", "expect("],
    expectNotContains: ["test("] // tu equipo usa it(), no test()
  }
];
```

### Fase 5: Deploy y Monitoreo üöÄ

```javascript
// Uso del modelo fine-tuned
const completion = await openai.createCompletion({
  model: "ft:gpt-3.5-turbo:my-company:suffix",
  prompt: "Create button component",
  max_tokens: 500
});
```

## Costes y ROI

### Inversi√≥n Inicial

**OpenAI GPT-3.5 Turbo**:
```
Training: ~$0.008 por 1K tokens
- Dataset de 100K tokens: ~$0.80
- Dataset de 1M tokens: ~$8

Uso despu√©s:
- Input: ~$0.012 por 1K tokens (vs $0.001 base)
- Output: ~$0.016 por 1K tokens (vs $0.002 base)

Coste: 12-16x m√°s caro que modelo base
```

**OpenAI GPT-4**:
```
Training: Contactar sales (enterprise)
Uso: Significativamente m√°s caro

Mejor para: Equipos grandes con budget
```

**Self-hosted (CodeLlama + LoRA)**:
```
Training:
- GPU time: $50-200 (seg√∫n cloud provider)
- Una sola vez

Uso:
- Infraestructura propia: $100-500/mes
- 0 coste por request

Mejor para: Proyectos grandes, largo plazo
```

### ROI Esperado

**Para equipo de 5 developers**:
```
Sin fine-tuning:
- Tiempo en formatting/fixing c√≥digo IA: 2h/d√≠a/persona
- 10 horas/d√≠a equipo = ~$500/d√≠a

Con fine-tuning:
- Coste mensual: ~$100-500
- Tiempo ahorrado: 50-70% en fixes
- ROI: Positivo desde semana 1
```

## Alternativas al Fine-tuning

### RAG (Retrieval-Augmented Generation)

**Qu√© es**:
```
En lugar de entrenar modelo, le das contexto din√°micamente:

T√∫: "Create button component"

Sistema RAG:
1. Busca en tu codebase componentes similares
2. Incluye ejemplos en el prompt
3. IA genera bas√°ndose en ejemplos

Ventajas:
‚úì Mucho m√°s barato
‚úì M√°s f√°cil de implementar
‚úì Actualizaciones en tiempo real
‚úì No requiere re-training

Desventajas:
‚úó Menos "internalizado" que fine-tuning
‚úó Requiere buenos embeddings
‚úó Limitado por context window
```

### Few-shot Prompting

**Qu√© es**:
```typescript
T√∫: `
Aqu√≠ est√°n 3 ejemplos de nuestros componentes:

EJEMPLO 1:
${componentExample1}

EJEMPLO 2:
${componentExample2}

EJEMPLO 3:
${componentExample3}

Ahora crea un componente Button similar:
`

Ventajas:
‚úì Gratis
‚úì Inmediato
‚úì Flexible

Desventajas:
‚úó Consume muchos tokens
‚úó No escala bien
‚úó Limitado a pocos ejemplos
```

### Comparaci√≥n

| M√©todo | Coste | Setup | Calidad | Mejor Para |
|--------|-------|-------|---------|------------|
| Fine-tuning | Alto | Complejo | M√°xima | Enterprise, largo plazo |
| RAG | Medio | Moderado | Alta | Equipos medianos |
| Few-shot | Bajo | Simple | Media | Proyectos peque√±os |

## Cu√°ndo SI Hacer Fine-tuning

‚úÖ **Vale la pena si**:
```
‚úì Equipo de 5+ developers
‚úì Codebase grande (50K+ l√≠neas)
‚úì Patrones muy espec√≠ficos
‚úì Alto volumen de uso diario
‚úì ROI claro (tiempo ahorrado > coste)
‚úì Budget para experimento
```

## Cu√°ndo NO Hacer Fine-tuning

‚ùå **No vale la pena si**:
```
‚úó Equipo peque√±o (1-3 personas)
‚úó Proyecto corto o temporal
‚úó Codebase peque√±o o gen√©rico
‚úó Bajo uso de IA
‚úó Sin budget para experimentos
‚úó RAG/Few-shot suficiente
```

## Mejores Pr√°cticas

### 1. Empieza con RAG

```
Orden recomendado:
1. Prueba few-shot prompting (gratis)
2. Implementa RAG si necesitas m√°s (barato)
3. Solo entonces considera fine-tuning (caro)
```

### 2. Itera Incremental

```
No fine-tunees todo de una:

Iteraci√≥n 1: Solo componentes React
Iteraci√≥n 2: A√±ade hooks y utils
Iteraci√≥n 3: A√±ade tests
Iteraci√≥n 4: A√±ade configuraciones
```

### 3. Mant√©n Versionado

```
my-model-v1 ‚Üí Componentes b√°sicos
my-model-v2 ‚Üí + Hooks y context
my-model-v3 ‚Üí + Testing patterns
my-model-v4 ‚Üí + Full stack

Permite rollback si algo falla
```

### 4. Documenta Todo

```markdown
# Model: my-company-fe-v2

## Training Data
- 500 React components (src/components/)
- 200 custom hooks (src/hooks/)
- 300 tests (*.test.tsx)

## Known Good At
- Creating components with our patterns
- Writing tests with Testing Library
- Using our design tokens

## Known Limitations
- Backend code (not trained)
- Legacy components (excluded)
- CSS-in-JS (we use styled-components only)

## Cost
- Training: $15
- Usage: ~$0.016/1K output tokens

## Metrics
- Pass rate on validation: 94%
- Time saved: ~30% vs base model
```

## Herramientas y Platforms

### OpenAI Platform
```bash
# CLI oficial
pip install openai

# Web dashboard
https://platform.openai.com/finetune
```

### Hugging Face
```python
# Para modelos open source
from transformers import Trainer, TrainingArguments
# ... extensive ecosystem
```

### LangChain + Custom
```python
# Para implementar RAG o fine-tuning custom
from langchain import LLM, PromptTemplate
# ... flexible framework
```

## Conclusi√≥n Clave

Fine-tuning es **especializaci√≥n mediante entrenamiento**:

- Transforma modelo general ‚Üí experto en TU c√≥digo
- Costoso pero potente para equipos grandes
- Para la mayor√≠a, RAG es suficiente y m√°s pr√°ctico

**Regla pr√°ctica**:
```
Equipo peque√±o ‚Üí Few-shot prompting
Equipo mediano ‚Üí RAG
Equipo grande + presupuesto ‚Üí Fine-tuning
```

**Recuerda**: Fine-tuning no es magia. Necesitas:
1. Datos de calidad
2. Casos de uso claros
3. M√©tricas de √©xito
4. Presupuesto adecuado

## Relaci√≥n con Otros Conceptos

- **[LLM](./01-llm.md)**: Fine-tuning crea versi√≥n especializada de un LLM
- **[Entrenamiento](./11-entrenamiento.md)**: Fine-tuning es re-entrenamiento parcial
- **[Modelo](./02-modelo.md)**: Creas un nuevo modelo derivado del base
- **[Agente](./08-agente.md)**: Agentes fine-tuned son m√°s efectivos en tu dominio

---

**Siguiente**: Aprende sobre [Entrenamiento](./11-entrenamiento.md) y c√≥mo los modelos aprenden.

[‚Üê Volver a Conceptos](../README.md#conceptos)
