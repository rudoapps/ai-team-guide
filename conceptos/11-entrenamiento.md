# Entrenamiento

## Â¿QuÃ© es el Entrenamiento?

**DefiniciÃ³n simple:** El proceso de enseÃ±ar a un modelo de IA a realizar tareas mediante exposiciÃ³n masiva a ejemplos y ajuste de sus parÃ¡metros internos.

**AnalogÃ­a:** Como enseÃ±ar a alguien a programar mostrÃ¡ndole **millones de ejemplos** de cÃ³digo hasta que aprenda patrones y pueda generar cÃ³digo por sÃ­ mismo.

```
Humano aprende: Lee 100 tutoriales â†’ PrÃ¡ctica 1000 horas â†’ Experto
IA aprende: Procesa 100M ejemplos â†’ Ajusta parÃ¡metros â†’ Modelo entrenado
```

## El Proceso de Aprendizaje

### Fase 1: RecolecciÃ³n de Datos ğŸ“š

**Para modelo de cÃ³digo**:
```
Input: Todo GitHub pÃºblico
- Millones de repos
- Miles de millones de lÃ­neas de cÃ³digo
- MÃºltiples lenguajes
- Diferentes estilos y patterns

Resultado: Dataset masivo de cÃ³digo
```

**Para modelo general**:
```
Input: Internet
- Wikipedia
- Libros digitalizados
- ArtÃ­culos cientÃ­ficos
- CÃ³digo open source
- DocumentaciÃ³n tÃ©cnica
- Conversaciones (Reddit, Stack Overflow)

Resultado: Conocimiento humano digitalizado
```

### Fase 2: Pre-entrenamiento ğŸ§ 

**QuÃ© sucede**:
```python
# Simplificado
for millions_of_examples in dataset:
    input_text = "function calculate"
    expected_next = "Sum"

    model_predicts = model.predict_next(input_text)
    error = expected_next - model_predicts

    model.adjust_parameters(error)
    # Repite millones de veces
```

**Recursos necesarios**:
```
GPT-4 training:
- Tiempo: Varios meses
- GPUs: Miles de GPUs A100
- Coste: Estimado $100M+
- EnergÃ­a: Megawatts
- Dataset: Terabytes de texto

Por eso tÃº NO entrenas GPT-4 desde cero
```

**Resultado**:
```
Modelo que "entiende":
âœ“ Sintaxis de lenguajes de programaciÃ³n
âœ“ Patrones comunes de cÃ³digo
âœ“ Buenas prÃ¡cticas generales
âœ“ DocumentaciÃ³n y APIs pÃºblicas
âœ“ Relaciones entre conceptos

Pero NO conoce:
âœ— Tu cÃ³digo especÃ­fico
âœ— Tu arquitectura
âœ— Tus convenciones
âœ— Eventos despuÃ©s de training cutoff
```

### Fase 3: Fine-tuning (Opcional) ğŸ¯

**EspecializaciÃ³n**:
```
Pre-trained model: Conoce cÃ³digo en general
      â†“
Fine-tuning con tu cÃ³digo
      â†“
Specialized model: Conoce TU manera de codificar
```

### Fase 4: RLHF (Reinforcement Learning from Human Feedback) ğŸ®

**QuÃ© es**:
```
Humanos evalÃºan outputs:

Output A: "AquÃ­ estÃ¡ el cÃ³digo [genera cÃ³digo correcto]"
Output B: "No puedo ayudar con eso"

Humanos marcan A como mejor
â†“
Modelo aprende a preferir respuestas Ãºtiles
```

**Por quÃ© es importante**:
```
Sin RLHF: Modelo tÃ©cnicamente correcto pero puede ser:
- Verboso
- Poco Ãºtil
- Ignora instrucciones
- Genera cÃ³digo inseguro

Con RLHF: Modelo que:
âœ“ Sigue instrucciones
âœ“ Es conciso y Ãºtil
âœ“ Rechaza peticiones peligrosas
âœ“ Admite cuando no sabe
```

## CÃ³mo los Datos de Entrenamiento Afectan el Comportamiento

### Ejemplo 1: Lenguajes de ProgramaciÃ³n

**Datos de entrenamiento**:
```
JavaScript: 40% del cÃ³digo de entrenamiento
Python: 30%
Java: 15%
Rust: 2%
Lenguaje obscuro X: 0.01%
```

**Resultado en el modelo**:
```
TÃº: "Escribe servidor web"

JS/Python: âœ… Excelente cÃ³digo, mÃºltiples opciones
Java: âœ… Buen cÃ³digo, patterns conocidos
Rust: âš ï¸ CÃ³digo correcto pero patterns menos idiomÃ¡ticos
Lenguaje X: âŒ Probablemente alucinarÃ¡ o darÃ¡ cÃ³digo malo
```

### Ejemplo 2: Frameworks y LibrerÃ­as

**Datos de entrenamiento**:
```
React: Millones de ejemplos
Vue: Miles de ejemplos
Framework nuevo (2024): Cero ejemplos (post cutoff)
```

**Resultado**:
```
React: IA experta, conoce hooks, patterns, ecosistema
Vue: IA competente, conoce bÃ¡sicos y algunos patterns
Framework 2024: IA no lo conoce, inventarÃ¡ sintaxis
```

### Ejemplo 3: Calidad del CÃ³digo

**Problema real**:
```
Datos incluyen:
âœ“ CÃ³digo excelente de repos top
âœ“ CÃ³digo promedio de millones de repos
âœ— CÃ³digo terrible de tutoriales malos
âœ— CÃ³digo buggeado
âœ— CÃ³digo deprecated

Resultado: IA puede sugerir cÃ³digo de cualquier calidad
```

**Por eso necesitas**:
```javascript
// Siempre revisar cÃ³digo generado
const generated = await ai.generateCode();

// Verificar:
âœ“ Â¿Usa APIs actuales?
âœ“ Â¿Sigue best practices?
âœ“ Â¿Tiene tests?
âœ“ Â¿Es seguro?
âœ“ Â¿Performance OK?

// NO asumir que es perfecto
```

## Limitaciones del Entrenamiento

### 1. Cutoff Date (Fecha de Corte) ğŸ“…

**Concepto**:
```
GPT-4 (versiÃ³n original):
- Entrenado hasta: Septiembre 2021
- No sabe: Nada despuÃ©s de sept 2021

Claude 3:
- Entrenado hasta: Agosto 2023
- No sabe: Nada despuÃ©s de agosto 2023
```

**Impacto**:
```
âŒ TÃº: "Â¿CÃ³mo uso React 19 server components?"
    IA: [Si React 19 es post-cutoff, alucinarÃ¡]

âœ… TÃº: "Â¿CÃ³mo uso React 18 hooks?"
    IA: [React 18 estÃ¡ en training, respuesta correcta]
```

### 2. Sesgos en los Datos ğŸ¯

**Problema**:
```
Si entrenamiento incluye:
- CÃ³digo principalmente de empresas tech USA
- DocumentaciÃ³n en inglÃ©s
- Proyectos open source (mÃ¡s experimentos que prod)

Resultado:
âš ï¸ Mejor en inglÃ©s que otros idiomas
âš ï¸ Favorece patterns de Silicon Valley
âš ï¸ Puede sugerir cÃ³digo experimental vs. estable
```

**Ejemplo real**:
```typescript
TÃº: "Crea componente de formulario"

IA puede sugerir:
- LibrerÃ­a muy nueva y experimental (vio en GitHub)
En lugar de:
- React Hook Form o Formik (battle-tested)

Por quÃ©: Proyectos experimentales son mÃ¡s visibles
en repos pÃºblicos que cÃ³digo de producciÃ³n privado
```

### 3. DistribuciÃ³n Desigual ğŸ“Š

**QuÃ© sucede**:
```
Stack popular (MERN):
- Millones de ejemplos
- Patterns bien establecidos
â†’ IA es excelente

Stack menos comÃºn:
- Miles de ejemplos
- Menos documentaciÃ³n pÃºblica
â†’ IA es mediocre

Tu stack especÃ­fico:
- Cero ejemplos (cÃ³digo privado)
â†’ IA debe generalizar
```

## Por QuÃ© la IA Sabe Unas Cosas y Otras No

### Lo que Sabe Bien âœ…

**1. CÃ³digo y patrones comunes**:
```javascript
// IA excelente en:
- Funciones JavaScript standard
- Componentes React bÃ¡sicos
- Express routes
- SQL queries comunes
- Configuraciones tÃ­picas
```

**2. DocumentaciÃ³n pÃºblica**:
```
âœ“ APIs de Node.js
âœ“ DocumentaciÃ³n de React
âœ“ MDN Web Docs
âœ“ Tutoriales populares
âœ“ Stack Overflow top questions
```

**3. Conceptos fundamentales**:
```
âœ“ Algoritmos clÃ¡sicos
âœ“ Patrones de diseÃ±o
âœ“ Principios de arquitectura
âœ“ Best practices establecidas
```

### Lo que NO Sabe âŒ

**1. CÃ³digo privado/propietario**:
```
âœ— Tu arquitectura especÃ­fica
âœ— Tu design system interno
âœ— Tus helpers y utilities custom
âœ— Tus convenciones de naming
âœ— Tus patterns especÃ­ficos
```

**2. InformaciÃ³n post-cutoff**:
```
âœ— Features nuevos de lenguajes
âœ— Versiones recientes de frameworks
âœ— LibrerÃ­as lanzadas recientemente
âœ— Breaking changes recientes
âœ— Vulnerabilidades descubiertas despuÃ©s
```

**3. Conocimiento especÃ­fico de nicho**:
```
âœ— Frameworks muy nuevos o oscuros
âœ— Protocolos propietarios
âœ— APIs internas de empresas
âœ— Casos edge muy especÃ­ficos
```

## EvoluciÃ³n de los Modelos

### GPT-3 (2020)
```
Training data hasta: 2019
TamaÃ±o: 175B parÃ¡metros
Fortalezas:
- Buen lenguaje natural
- CÃ³digo bÃ¡sico

Debilidades:
- CÃ³digo complejo limitado
- Sigue mal instrucciones
- Muchas alucinaciones
```

### GPT-4 (2023)
```
Training data hasta: 2021-2022
TamaÃ±o: Estimado 1.7T parÃ¡metros
Fortalezas:
- Razonamiento avanzado
- CÃ³digo complejo
- Sigue instrucciones mejor
- Multimodal (texto + imÃ¡genes)

Debilidades:
- AÃºn alucina
- Costoso
- A veces verboso
```

### Claude 3 (2024)
```
Training data hasta: 2023
CaracterÃ­sticas:
- Context window masivo (200K tokens)
- Excelente en anÃ¡lisis de cÃ³digo
- Menos propenso a alucinaciÃ³n

Fortalezas especÃ­ficas:
- Leer codebases enteros
- AnÃ¡lisis profundo
- Respuestas concisas
```

### Especializados (Codex, CodeLlama)
```
Training data: Principalmente cÃ³digo
Fortalezas:
- GeneraciÃ³n de cÃ³digo superior
- Autocompletado preciso
- MÃºltiples lenguajes

Debilidades:
- Peor en conversaciÃ³n general
- Limitado a cÃ³digo
```

## Impacto en tu Trabajo Diario

### Entiende las Fortalezas

**Para cÃ³digo standard**:
```typescript
âœ… "Crea funciÃ³n para validar email con regex"
// â†’ IA excelente, pattern muy comÃºn

âœ… "Implementa binary search en TypeScript"
// â†’ IA excelente, algoritmo clÃ¡sico
```

**Para cÃ³digo especÃ­fico**:
```typescript
âš ï¸ "Crea componente siguiendo NUESTRO design system"
// â†’ Necesitas dar ejemplos o contexto

âš ï¸ "Implementa usando NUESTRA arquitectura CQRS custom"
// â†’ Necesitas explicar tu arquitectura
```

### Mitiga las Debilidades

**Proporciona contexto**:
```
âŒ "Refactoriza este componente"

âœ… "Refactoriza este componente siguiendo este patrÃ³n:
    [pega ejemplo de tu codebase]
    Usa styled-components y nuestros design tokens
    que estÃ¡n en src/tokens/"
```

**Verifica informaciÃ³n reciente**:
```
âŒ Confiar ciegamente en info sobre versiones recientes

âœ… Cuando IA menciona versiÃ³n reciente:
   â†’ Verifica en docs oficiales
   â†’ Busca en changelog
   â†’ Prueba en proyecto de test
```

### Usa EstratÃ©gicamente

**Tareas donde training ayuda**:
```
âœ… Boilerplate y setup inicial
âœ… Refactoring de patterns conocidos
âœ… Tests de lÃ³gica comÃºn
âœ… DocumentaciÃ³n standard
âœ… ConversiÃ³n entre lenguajes populares
```

**Tareas donde training limita**:
```
âš ï¸ CÃ³digo de tu dominio especÃ­fico
âš ï¸ IntegraciÃ³n con tus sistemas internos
âš ï¸ Features de Ãºltimas versiones
âš ï¸ Optimizaciones avanzadas
âš ï¸ Decisiones de arquitectura contextual
```

## El Futuro del Entrenamiento

### Tendencias Emergentes

**1. Training continuo**:
```
Modelos que se actualizan frecuentemente:
- Reducir gap de conocimiento
- Conocer features recientes
- Adaptarse a nuevas librerÃ­as
```

**2. EspecializaciÃ³n**:
```
Modelos especÃ­ficos por dominio:
- CodeLlama para cÃ³digo
- Copilot para GitHub
- Modelos mÃ©dicos, legales, etc.
```

**3. PersonalizaciÃ³n**:
```
Modelos que aprenden de tu uso:
- Tu estilo de cÃ³digo
- Tus preferencias
- Tu contexto especÃ­fico
```

## ConclusiÃ³n Clave

El entrenamiento determina **todo lo que la IA puede y no puede hacer**:

```
Sus conocimientos â† Datos de entrenamiento
Sus sesgos â† Sesgos en los datos
Sus limitaciones â† Gaps en los datos
Sus fortalezas â† Ãreas bien representadas
```

**Para trabajar efectivamente con IA**:
1. Entiende quÃ© sabe bien (cÃ³digo comÃºn, pÃºblico, popular)
2. Entiende quÃ© NO sabe (tu cÃ³digo, post-cutoff, nicho)
3. Compensa con contexto donde sea necesario
4. Verifica siempre cÃ³digo crÃ­tico

**PiÃ©nsalo asÃ­**: La IA es como un developer que:
- LeyÃ³ millones de repos de GitHub
- EstudiÃ³ toda la documentaciÃ³n pÃºblica
- Nunca olvidarÃ¡ nada de eso
- Pero nunca trabajÃ³ en TU proyecto especÃ­fico

Tu trabajo: Darle el contexto que le falta para ser efectiva en TU cÃ³digo.

## RelaciÃ³n con Otros Conceptos

- **[LLM](./01-llm.md)**: El entrenamiento crea el LLM
- **[Modelo](./02-modelo.md)**: Cada modelo es resultado de training diferente
- **[Fine-tuning](./10-fine-tuning.md)**: Es re-entrenamiento especializado
- **[AlucinaciÃ³n](./09-alucinacion.md)**: Limitaciones del training causan alucinaciones
- **[Token](./03-token.md)**: El training enseÃ±a al modelo a tokenizar

---

**Hecho**: Has completado todos los conceptos fundamentales de IA para desarrollo.

[â† Volver a Conceptos](../README.md#conceptos)
